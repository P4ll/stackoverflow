{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/p4l/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import logging\n",
    "import pickle\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from scipy.stats import entropy\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "from scipy.special import (entr, rel_entr)\n",
    "from numpy import (arange, putmask, ravel, ones, shape, ndarray, zeros, floor,\n",
    "                   logical_and, log, sqrt, place, argmax, vectorize, asarray,\n",
    "                   nan, inf, isinf, NINF, empty)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "my_stop_words = STOPWORDS.union(set(['use', 'be', 'work', 'user', 'try', 'cell',\n",
    "                                     'row', 'want', 'item', 'go', 'get', 'add', 'went', 'tried',\n",
    "                                    'return', 'sort', 'test', 'run', 'check', 'click', 'hour', 'minute', 'second',\n",
    "                                    'version', 'app', 'paragraph', 'error', 'log', 'press',\n",
    "                                    'need', 'feed', 'thank', 'way', 'like', 'kill', 'help']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/p4l/work/stackoverflow/\"\n",
    "base_model = base_path + \"models_data/\"\n",
    "base_dataset = base_path + \"dataset/\"\n",
    "base_model_lda = base_model + \"lda/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub('<code>(.|\\n)*?<\\/code>', '', text)\n",
    "    text = re.sub(r'(\\<(/?[^>]+)>)', '', text)\n",
    "    text = re.sub(\"[\\'\\\"\\\\/\\@\\%\\(\\)\\~\\`\\{\\}]\", '', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = clear_text(text)\n",
    "    result = []\n",
    "    #result = [token in gensim.utils.simple_preprocess(text, deacc=True) if ((token not in gensim.parsing.preprocessing.STOPWORDS) and len(token) > 1) == True]\n",
    "    for token in gensim.utils.simple_preprocess(text, deacc=True):\n",
    "        if (token not in my_stop_words) and len(token) > 1:\n",
    "            #result.append(lemmatize_stemming(token))\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "def split_tags(text):\n",
    "    if not isinstance(text, str) and math.isnan(text):\n",
    "        return ''\n",
    "    if text == '' or text == ' ':\n",
    "        return text\n",
    "    else:\n",
    "        return text.replace('|', ' ')\n",
    "\n",
    "def add_string(text, tags, n=3):\n",
    "    tags = split_tags(tags)\n",
    "    tags = ' ' + tags\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        if i % 2 == 0:\n",
    "            text += tags\n",
    "        else:\n",
    "            text = tags + text\n",
    "    return text\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags and not token.lemma_ in my_stop_words])\n",
    "    return texts_out\n",
    "\n",
    "def get_text_bow(text):\n",
    "    text = preprocess(text)\n",
    "    text = make_trigrams([text])[0]\n",
    "    text = lemmatization([text])[0]\n",
    "    bow_vector = dictionary.doc2bow(text)\n",
    "    return bow_vector\n",
    "\n",
    "def test_texts(text1, text2):\n",
    "    bow1 = get_text_bow(text1)\n",
    "    bow2 = get_text_bow(text2)\n",
    "    sc1 = 0.0\n",
    "    sc2 = 0.0\n",
    "    for index, score in sorted(lda_model[bow1], key=lambda tup: -1*tup[1]):\n",
    "        print(f\"index: {index}, score {score}\")\n",
    "        sc1 += score\n",
    "        #print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))\n",
    "    print(\"_________________________________________\")\n",
    "    for index, score in sorted(lda_model[bow2], key=lambda tup: -1*tup[1]):\n",
    "        print(f\"index: {index}, score {score}\")\n",
    "        sc2 += score\n",
    "    return (sc1, sc2)\n",
    "        \n",
    "def jensen_shannon_v(p, q):\n",
    "    p = p[None,:].T\n",
    "    q = q[None,:].T\n",
    "    m = 0.5*(p + q)\n",
    "    #print(m)\n",
    "    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))\n",
    "\n",
    "def title_body_sim(text1, text2, n_topics):\n",
    "    bow1 = get_text_bow(text1)\n",
    "    bow2 = get_text_bow(text2)\n",
    "    p = np.zeros(n_topics)\n",
    "    q = np.zeros(n_topics)\n",
    "    for index, score in sorted(lda_model[bow1], key=lambda tup: -1*tup[1]):\n",
    "        p[index] = score\n",
    "    for index, score in sorted(lda_model[bow2], key=lambda tup: -1*tup[1]):\n",
    "        q[index] = score\n",
    "\n",
    "    return jensen_shannon_v(p, q)\n",
    "\n",
    "def distr(arr):\n",
    "    max_len = len(arr)\n",
    "    mat = []\n",
    "    mat.append([1.0 for i in range(max_len)])\n",
    "    for i in range(max_len - 1):\n",
    "        z = [0.0 for k in range(max_len)]\n",
    "        z[i] = arr[i + 1]\n",
    "        z[i + 1] = -arr[i]\n",
    "        mat.append(z)\n",
    "    vec = np.zeros(max_len)\n",
    "    vec[0] = 1.0\n",
    "    mat = np.array(mat)\n",
    "    print(mat)\n",
    "    print(vec)\n",
    "    #return np.linalg.solve(mat, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel.load(datapath(base_model_lda + \"model_semi_final\"))\n",
    "bigram_mod = gensim.models.phrases.Phraser.load(datapath(base_model + \"ngrams/bigram_mod\"))\n",
    "trigram_mod = gensim.models.phrases.Phraser.load(datapath(base_model + \"ngrams/trigram_mod\"))\n",
    "dictionary = gensim.corpora.Dictionary.load(datapath(base_model_lda + \"model_semi_final.id2word\"))\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"Using index from a list to get another value/element in another list\"\"\"\n",
    "\n",
    "text2 = \"\"\"                   <p>I have project wherein I have to get the index of certain element in a list, then use that index to get another value in another list. </p>\n",
    "\n",
    "<p>For example,</p>\n",
    "\n",
    "<pre class=\"lang-py prettyprint prettyprinted\" style=\"\"><code><span class=\"pln\">j_set </span><span class=\"pun\">=</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">1</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">2</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">3</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">4</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">5</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">6</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">7</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">8</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">9</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">10</span><span class=\"pun\">]</span><span class=\"pln\">\n",
    "on_going </span><span class=\"pun\">=</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">1</span><span class=\"pun\">]</span><span class=\"pln\">\n",
    "e_list </span><span class=\"pun\">=</span><span class=\"pln\"> </span><span class=\"pun\">[[],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">1</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">1</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">2</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">3</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">3</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">5</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">4</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">7</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">6</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">8</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">9</span><span class=\"pun\">],</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"lit\">10</span><span class=\"pun\">]]</span></code></pre>\n",
    "\n",
    "<p>So far, the code looks like this:</p>\n",
    "\n",
    "<pre class=\"lang-py prettyprint prettyprinted\" style=\"\"><code><span class=\"kwd\">if</span><span class=\"pln\"> isinstance</span><span class=\"pun\">(</span><span class=\"pln\">on_going</span><span class=\"pun\">,</span><span class=\"pln\"> int</span><span class=\"pun\">):</span><span class=\"pln\">\n",
    "    on_going </span><span class=\"pun\">=</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"pln\">on_going</span><span class=\"pun\">]</span><span class=\"pln\">\n",
    "idx </span><span class=\"pun\">=</span><span class=\"pln\"> </span><span class=\"pun\">[</span><span class=\"pln\">y </span><span class=\"kwd\">for</span><span class=\"pln\"> y</span><span class=\"pun\">,</span><span class=\"pln\"> x </span><span class=\"kwd\">in</span><span class=\"pln\"> enumerate</span><span class=\"pun\">(</span><span class=\"pln\">e_list</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"kwd\">if</span><span class=\"pln\"> x </span><span class=\"kwd\">in</span><span class=\"pln\"> on_going</span><span class=\"pun\">]</span><span class=\"pln\"> </span><span class=\"com\"># code to get index in e_list</span><span class=\"pln\">\n",
    "</span><span class=\"kwd\">print</span><span class=\"pun\">(</span><span class=\"pln\">idx</span><span class=\"pun\">)</span><span class=\"pln\">\n",
    "\n",
    "</span><span class=\"kwd\">for</span><span class=\"pln\"> i </span><span class=\"kwd\">in</span><span class=\"pln\"> idx</span><span class=\"pun\">:</span><span class=\"pln\">\n",
    "    q_active </span><span class=\"pun\">=</span><span class=\"pln\"> j_set</span><span class=\"pun\">.</span><span class=\"pln\">append</span><span class=\"pun\">(</span><span class=\"pln\">i</span><span class=\"pun\">)</span><span class=\"pln\">\n",
    "    </span><span class=\"kwd\">print</span><span class=\"pun\">(</span><span class=\"pln\">q_active</span><span class=\"pun\">)</span></code></pre>\n",
    "\n",
    "<p>The objective is to get the corresponding <code>index</code> of value/element in <code>on_going</code> from <code>e_list</code>. Then, use that index to get corresponding activity from <code>j_set</code> and store in <code>q_active</code>.</p>\n",
    "\n",
    "<p>Expected output is: <code>q_active = [2, 3]</code> from the example shown above.</p>\n",
    "\n",
    "<p>The problem is, with the code above, I am getting an output for storing values in q_active as:</p>\n",
    "\n",
    "<pre class=\"lang-py prettyprint prettyprinted\" style=\"\"><code><span class=\"pun\">[</span><span class=\"lit\">1</span><span class=\"pun\">,</span><span class=\"pln\"> </span><span class=\"lit\">2</span><span class=\"pun\">]</span><span class=\"pln\">\n",
    "</span><span class=\"kwd\">None</span><span class=\"pln\">\n",
    "</span><span class=\"kwd\">None</span></code></pre>\n",
    "\n",
    "<p>Any help would be appreciated! Thanks!</p>\n",
    "    </div>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 123, score 0.5008334517478943\n",
      "index: 120, score 0.25083300471305847\n",
      "_________________________________________\n",
      "index: 33, score 0.16809387505054474\n",
      "index: 186, score 0.11650429666042328\n",
      "index: 120, score 0.11124513298273087\n",
      "index: 30, score 0.08400005102157593\n",
      "index: 240, score 0.075936459004879\n",
      "index: 123, score 0.07469457387924194\n",
      "index: 130, score 0.04107626900076866\n",
      "index: 276, score 0.040155280381441116\n",
      "index: 187, score 0.03757336735725403\n",
      "index: 272, score 0.03751949965953827\n",
      "index: 125, score 0.03716368228197098\n",
      "index: 62, score 0.03716365620493889\n",
      "index: 0, score 0.03716309741139412\n",
      "index: 53, score 0.037084124982357025\n",
      "index: 194, score 0.02943793497979641\n",
      "(0.7516664564609528, 0.9648113008588552)\n"
     ]
    }
   ],
   "source": [
    "print(test_texts(text1, text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66803593])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_body_sim(text1, text2, lda_model.num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
